# Projet PrÃ©vision MÃ©tÃ©o en Australie - MLOps Juillet 2024 â˜€ï¸ğŸŒ§ï¸

Ce projet dÃ©ploie un modÃ¨le **Random Forest** ğŸŒ² dans une application de prÃ©vision de pluie Ã  J+1 sur une ville donnÃ©e en Australie ğŸ‡¦ğŸ‡º. Le projet intÃ¨gre des outils MLOps tels que **Airflow** ğŸ—ï¸, **MLflow** ğŸš€ pour la pipeline data-model, **Prometheus** ğŸ“ˆ et **Grafana** ğŸ“Š pour le monitoring des ressources machines, ainsi que **FastAPI** âš¡ et **Streamlit** ğŸ¨ pour l'infÃ©rence.

## Table des matiÃ¨res ğŸ“š

- [Description du projet](#description-du-projet-)
- [Architecture du projet](#architecture-du-projet-)
- [Les DAGs Airflow](#les-dags-airflow-)
- [Outils utilisÃ©s](#outils-utilisÃ©s-)
- [Installation et utilisation](#installation-et-utilisation-)
  - [Version de production](#version-de-production-)
  - [Version de dÃ©veloppement](#version-de-dÃ©veloppement-)
  - [AccÃ¨s aux services](#accÃ¨s-aux-services-)
- [CI/CD](#cicd-)
- [Monitoring](#monitoring-)
- [Licence](#licence-)
- [Ã‰quipe du projet](#Ã©quipe-du-projet-)

---

## Description du projet ğŸ“

Le projet vise Ã  prÃ©dire la probabilitÃ© de pluie le lendemain pour une ville spÃ©cifique en Australie. Il s'appuie sur un modÃ¨le **Random Forest** ğŸŒ² entraÃ®nÃ© sur des donnÃ©es mÃ©tÃ©orologiques actualisÃ©es quotidiennement. Les principaux composants du projet sont :

- **Airflow** ğŸ—ï¸ pour orchestrer les pipelines de donnÃ©es (ETL) et l'entraÃ®nement du modÃ¨le.
- **MLflow** ğŸš€ pour gÃ©rer les expÃ©riences de machine learning et suivre les performances des modÃ¨les.
- **FastAPI** âš¡ et **Streamlit** ğŸ¨ pour fournir une interface utilisateur pour les prÃ©dictions et une interface administrateur pour gÃ©rer les mises Ã  jour et les entraÃ®nements.
- **Prometheus** ğŸ“ˆ et **Grafana** ğŸ“Š pour le monitoring des ressources serveurs et la visualisation des mÃ©triques.
- Utilisation de **Docker** ğŸ³ pour la containerisation et de **Docker Hub** ğŸ³ pour le dÃ©ploiement des images.
- **GitHub Actions** âš™ï¸ pour l'intÃ©gration continue et le dÃ©ploiement continu (CI/CD).

---

## Architecture du projet ğŸ›ï¸

![Architecture du Projet][] <!-- Assurez-vous d'inclure une image reprÃ©sentant l'architecture de votre projet -->

Le projet est entiÃ¨rement containerisÃ©, ce qui facilite le dÃ©ploiement et la scalabilitÃ©. L'architecture se compose des Ã©lÃ©ments suivants :

- **Scraping des donnÃ©es** ğŸ•¸ï¸ : RÃ©cupÃ©ration quotidienne des relevÃ©s mÃ©tÃ©orologiques via des scripts Python.
- **Pipeline ETL avec Airflow** ğŸ—ï¸ : Extraction, transformation et chargement des donnÃ©es dans une base de donnÃ©es PostgreSQL.
- **EntraÃ®nement du modÃ¨le avec MLflow** ğŸš€ : EntraÃ®nement hebdomadaire du modÃ¨le Random Forest, comparaison avec le modÃ¨le prÃ©cÃ©dent selon le F1-score, et dÃ©ploiement du meilleur modÃ¨le.
- **API d'infÃ©rence avec FastAPI** âš¡ : Fournit des prÃ©dictions basÃ©es sur le modÃ¨le dÃ©ployÃ©.
- **Interface utilisateur avec Streamlit** ğŸ¨ : Permet aux utilisateurs de faire des prÃ©dictions et aux administrateurs de lancer manuellement une rÃ©cupÃ©ration des donnÃ©es du jour et un entraÃ®nement avec sÃ©lection du meilleur modÃ¨le.
- **Monitoring avec Prometheus** ğŸ“ˆ et **Grafana** ğŸ“Š : Collecte et visualisation des mÃ©triques du systÃ¨me et des performances du modÃ¨le.
- **CI/CD avec GitHub Actions** âš™ï¸ : Tests automatisÃ©s et dÃ©ploiement continu sur Docker Hub.

---

## Les DAGs Airflow ğŸ“…

- **DAG de collecte des donnÃ©es (quotidien)**
  - **TÃ¢ches** :
    - Scraping du site mÃ©tÃ©orologique pour obtenir les relevÃ©s journaliers. ğŸŒ¦ï¸
    - Nettoyage et prÃ©paration des donnÃ©es. ğŸ§¹
    - Insertion des donnÃ©es dans la base de donnÃ©es PostgreSQL. ğŸ—„ï¸
- **DAG d'entraÃ®nement du modÃ¨le (hebdomadaire)**
  - **TÃ¢ches** :
    - Chargement des donnÃ©es depuis la base de donnÃ©es. ğŸ“¥
    - EntraÃ®nement du modÃ¨le Random Forest avec MLflow. ğŸš€
    - Comparaison avec le modÃ¨le prÃ©cÃ©dent en utilisant le F1-score. ğŸ“Š
    - Enregistrement du meilleur modÃ¨le pour l'infÃ©rence. ğŸ’¾
- **DAG combinÃ© (exÃ©cution manuelle)**
  - **TÃ¢ches** :
    - ExÃ©cution des tÃ¢ches de collecte des donnÃ©es. ğŸŒ
    - EntraÃ®nement du modÃ¨le et sÃ©lection du meilleur. ğŸ†
  - **Utilisation** :
    - Peut Ãªtre dÃ©clenchÃ© depuis le panneau administrateur de l'application Streamlit pour forcer une mise Ã  jour du modÃ¨le.
- **DAG de tests unitaires**
  - **TÃ¢ches** :
    - ExÃ©cution de la suite de tests pour valider le bon fonctionnement des pipelines et du modÃ¨le. âœ…

---

## Outils utilisÃ©s ğŸ› ï¸

- **Langage** : Python 3.8+ ğŸ
- **Outils MLOps** :
  - **Apache Airflow** ğŸ—ï¸ : Orchestration des pipelines ETL et des entraÃ®nements.
  - **MLflow** ğŸš€ : Gestion des expÃ©riences de machine learning et suivi des modÃ¨les.
- **DÃ©veloppement Web** :
  - **FastAPI** âš¡ : CrÃ©ation de l'API d'infÃ©rence.
  - **Streamlit** ğŸ¨ : Interface utilisateur pour les prÃ©dictions et les actions administratives.
- **Monitoring** :
  - **Prometheus** ğŸ“ˆ : Collecte des mÃ©triques systÃ¨me.
  - **Grafana** ğŸ“Š : Visualisation des mÃ©triques via des tableaux de bord.
- **Gestion des donnÃ©es** :
  - **PostgreSQL** ğŸ—„ï¸ : Base de donnÃ©es pour stocker les donnÃ©es prÃ©parÃ©es.
- **Containerisation et DÃ©ploiement** :
  - **Docker** ğŸ³ et **Docker Compose** ğŸ“¦ : Containerisation des services.
  - **Docker Hub** ğŸ³ : Stockage et distribution des images Docker.
  - **GitHub Actions** âš™ï¸ : IntÃ©gration continue et dÃ©ploiement continu (CI/CD).

---

## Installation et utilisation ğŸš€

### PrÃ©-requis ğŸ“‹

- **Docker** ğŸ³ et **Docker Compose** ğŸ“¦ installÃ©s sur votre machine.
- **Make** installÃ© pour utiliser les Makefiles.

### Version de production ğŸ­

1. **Initialiser Airflow** :

   ```bash
   make -f Makefile.prod init-airflow
   ```

2. **DÃ©marrer les services** :

   ```bash
   make -f Makefile.prod start
   ```

### Version de dÃ©veloppement ğŸ§‘â€ğŸ’»

1. **Initialiser Airflow** :

   ```bash
   make -f Makefile.dev init-airflow
   ```

2. **DÃ©marrer les services** :

   ```bash
   make -f Makefile.dev start
   ```

### AccÃ¨s aux services ğŸŒ

AprÃ¨s avoir dÃ©marrÃ© les services, vous pouvez accÃ©der aux diffÃ©rentes interfaces via les ports suivants :

- **Airflow** ğŸ—ï¸ : [http://localhost:8080](http://localhost:8080)
  - **Port** : `8080`
  - Interface Web pour superviser les DAGs et les tÃ¢ches.
- **MLflow** ğŸš€ : [http://localhost:5000](http://localhost:5000)
  - **Port** : `5000`
  - Interface pour visualiser les expÃ©riences de machine learning et les paramÃ¨tres des modÃ¨les.
- **FastAPI** âš¡ (API d'infÃ©rence) : [http://localhost:8000/docs](http://localhost:8000/docs)
  - **Port** : `8000`
  - Documentation interactive de l'API via Swagger UI.
- **Streamlit** ğŸ¨ : [http://localhost:8501](http://localhost:8501)
  - **Port** : `8501`
  - Interface utilisateur pour effectuer des prÃ©dictions et accÃ©der au panneau administrateur.

---

## Monitoring ğŸ“ˆ

**Prometheus** ğŸ“ˆ collecte les mÃ©triques systÃ¨me, telles que l'utilisation du CPU, de la mÃ©moire et des ressources rÃ©seau. **Grafana** ğŸ“Š est utilisÃ© pour visualiser ces mÃ©triques Ã  travers des tableaux de bord personnalisables.

- **AccÃ©der Ã  Grafana** :

  Rendez-vous sur [http://localhost:3000](http://localhost:3000) (port `3000`) et connectez-vous avec les identifiants par dÃ©faut (configurÃ©s dans le docker-compose).

- **Dashboards permettant de visualiser entre autres** :

  - Utilisation du CPU. ğŸ–¥ï¸
  - Utilisation de la mÃ©moire. ğŸ§ 
  - Utilisation du disque. ğŸ’¾
  - Utilisation du rÃ©seau. ğŸŒ
  - Performances des services Docker. ğŸ³

---

## CI/CD âš™ï¸

Le projet utilise **GitHub Actions** âš™ï¸ pour l'intÃ©gration continue et le dÃ©ploiement continu :

- **Tests automatisÃ©s** ğŸ§ª : Ã€ chaque push ou pull request, les tests unitaires sont exÃ©cutÃ©s pour s'assurer que le code est fonctionnel.
- **Build des images Docker** ğŸ³ : Les images Docker sont construites et testÃ©es.
- **DÃ©ploiement sur Docker Hub** ğŸ³ : Si les tests rÃ©ussissent, les images sont poussÃ©es sur Docker Hub avec un nouveau tag de version.


---

## Licence ğŸ“„

Ce projet est sous licence MIT - voir le fichier [LICENSE](./LICENSE) pour plus de dÃ©tails.

---

## Ã‰quipe du projet ğŸ‘¥

Ce projet a Ã©tÃ© dÃ©veloppÃ© par l'Ã©quipe suivante :

- **Shirley GERVOLINO** [![GitHub][]](https://github.com/Shirley687) / [![LinkedIn][]](https://www.linkedin.com/in/)
- **Tristan** [![GitHub][]](https://github.com/tristandatascience) / [![LinkedIn][]](https://www.linkedin.com/in/)
- **Prudence Amani** [![GitHub][]](https://github.com/) / [![LinkedIn][]](https://www.linkedin.com/in/)
- **StÃ©phane LOS** [![GitHub][]](https://github.com/hil-slos) / [![LinkedIn][]](https://fr.linkedin.com/in/losstephane/)

---

*Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du programme MLOps de Juillet 2024.*

---

**Note** : Assurez-vous de remplacer les liens manquants ou incomplets vers les profils LinkedIn par les liens corrects.

---

# Liens utiles ğŸ”—

- [Documentation du projet](Lien_vers_votre_documentation)
- [Docker Hub](https://hub.docker.com/u/votre_nom_utilisateur)
- [Issues](Lien_vers_votre_projet_GitHub/issues)

---

Les badges sont gÃ©nÃ©rÃ©s via [Shields.io](https://shields.io/) 
